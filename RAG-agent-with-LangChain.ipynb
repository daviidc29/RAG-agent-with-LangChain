{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59cf5ecb",
   "metadata": {},
   "source": [
    "# Lab Statement: Introduction to Creating RAGs (Retrieval-Augmented Generators) with OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223f292",
   "metadata": {},
   "source": [
    "## Name: David Santiago Castro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b04e64",
   "metadata": {},
   "source": [
    "### Overview\n",
    "One of the most powerful applications enabled by LLMs is sophisticated question-answering  chatbots. These are applications that can answer questions about specific source information. These applications use a technique known as Retrieval Augmented Generation, or RAG.\n",
    "\n",
    "### Concepts\n",
    "We will cover the following concepts:\n",
    "Indexing: a pipeline for ingesting data from a source and indexing it. This usually happens in a separate process.\n",
    "Retrieval and generation: the actual RAG process, which takes the user query at run time and retrieves the relevant data from the index, then passes that to the model.\n",
    "Once we’ve indexed our data, we will use an agent as our orchestration framework to implement the retrieval and generation steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921ef54",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8030428",
   "metadata": {},
   "source": [
    "We require these langchain dependencies:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e75a06ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.10)\n",
      "Requirement already satisfied: langchain-text-splitters in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: bs4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.10 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.2.14)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (9.1.4)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.7.6)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (2.0.46)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (2.13.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (3.13.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bs4) (4.14.3)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (0.14.1)\n",
      "Requirement already satisfied: packaging>=23.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (24.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (0.3.8)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (3.6.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (1.0.8)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.7)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.6.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->bs4) (2.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: anyio in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.1)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain) (1.12.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-text-splitters langchain-community bs4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5846b192",
   "metadata": {},
   "source": [
    "\n",
    "### LangSmith\n",
    "\n",
    "LangSmith is a tool that helps us see what is happening inside our LangChain applications. Since these applications often involve many steps and multiple LLM calls, it can be difficult to understand how everything works. LangSmith allows we to log and inspect the process, so we can track each step and debug more easily. To use it, we must first register and then configure our environment variables so that all activity in our chain or agent is logged for review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3f2f812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "load_dotenv()  \n",
    "\n",
    "langchain_tracing_v2 = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ad0f6",
   "metadata": {},
   "source": [
    "\n",
    "### Components\n",
    "We will need to select three components from LangChain’s suite of integrations. We select OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d96f2b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain[openai] in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.10)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.10)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain[openai]) (1.0.9)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.10 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain[openai]) (1.2.14)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain[openai]) (2.12.5)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=2.20.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openai) (2.21.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain[openai]) (0.7.6)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain[openai]) (1.33)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain[openai]) (9.1.4)\n",
      "Requirement already satisfied: packaging>=23.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain[openai]) (24.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain[openai]) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain[openai]) (0.14.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain[openai]) (6.0.3)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langgraph<1.1.0,>=1.0.8->langchain[openai]) (0.3.8)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langgraph<1.1.0,>=1.0.8->langchain[openai]) (3.6.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langgraph<1.1.0,>=1.0.8->langchain[openai]) (1.0.8)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langgraph<1.1.0,>=1.0.8->langchain[openai]) (4.0.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.13.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.12.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.67.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (0.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2026.1.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=2.20.0->langchain-openai) (3.11)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=2.20.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=2.20.0->langchain-openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=2.20.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=2.20.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain[openai]) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain[openai]) (1.12.2)\n",
      "Requirement already satisfied: orjson>=3.11.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain[openai]) (3.11.7)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain[openai]) (0.25.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain[openai]) (1.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>4->openai<3.0.0,>=2.20.0->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U \"langchain[openai]\" python-dotenv langchain-openai\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"gpt-4o\",\n",
    "    model_provider=\"openai\",\n",
    "    openai_api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "    openai_api_base=\"https://models.inference.ai.azure.com\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c184191",
   "metadata": {},
   "source": [
    "Select an embeddings model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "333c1b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    openai_api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "    openai_api_base=\"https://models.inference.ai.azure.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90ab78b",
   "metadata": {},
   "source": [
    "We selected Pinecone as the vector database as requested:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "76dc1122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "67ec88f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d58c9b",
   "metadata": {},
   "source": [
    "Before initializing our vector store, let’s connect to a Pinecone index. If one named index_name doesn’t exist, it will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c31fda9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = \"langchain-test-index-v2\" \n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3072,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "vector_store = PineconeVectorStore(embedding=embeddings, index=index)\n",
    "\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952fead4",
   "metadata": {},
   "source": [
    "### Indexing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f69864c",
   "metadata": {},
   "source": [
    "Indexing commonly works as follows:\n",
    "- Load: First we need to load our data. This is done with Document Loaders\n",
    "- Split: Text splitters break large Documents into smaller chunks. This is useful both for indexing data and passing it into a model, as large chunks are harder to search over and won’t fit in a model’s finite context window\n",
    "- Store: We need somewhere to store and index our splits, so that they can be searched over later. This is often done using a VectorStore and Embeddings model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ff9ef",
   "metadata": {},
   "source": [
    "### Loading documents\n",
    "\n",
    "We first need to load the blog post content, and for that we use DocumentLoaders, which are tools that bring in data from a source and turn it into a list of Document objects we can work with. In our case, we’ll use the WebBaseLoader, which relies on urllib to fetch HTML from web URLs and then uses BeautifulSoup to convert that HTML into text. We can adjust how BeautifulSoup does the parsing by passing parameters bs_kwargs. Since we only care about HTML tags with classes like post content, post title, or post header, we’ll filter out everything else so that we only keep the relevant text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "23d3c930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43047\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "338824d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a828e6",
   "metadata": {},
   "source": [
    "We start by using a DocumentLoader, which is an object that takes data from a source and turns it into a list of Documents we can work with. There are more than 160 integrations available, and the BaseLoader serves as the API reference for the core interface.\n",
    "Since our blog post has over 43,000 characters, it’s too long to fit into the context window of most models. Even if a model could handle the full text, searching through such a large input would be inefficient. To solve this, we split the document into smaller chunks that can be embedded and stored in a vector database. This way, at runtime we only retrieve the most relevant fragments instead of the entire post.\n",
    "For splitting, we use a RecursiveCharacterTextSplitter, which breaks the text down step by step using common separators like new lines. It keeps dividing until each chunk is the right size. This method is recommended for general text use cases because it balances efficiency with preserving meaningful structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bcdcad02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 63 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  \n",
    "    chunk_overlap=200,  \n",
    "    add_start_index=True,  \n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b44fac",
   "metadata": {},
   "source": [
    "We use a TextSplitter to break our list of Documents into smaller chunks, making them easier to store and retrieve later. Once we have these fragments, we need to index them so they can be searched at runtime. In our case, we ended up with 63 text chunks. Following the semantic search tutorial, our approach is to embed the content of each chunk and insert those embeddings into a vector store. This allows us to perform vector searches: when we get a query, we can quickly find and return only the most relevant pieces of text. The nice part is that we can embed and store all our document splits in one step, using the vector store and embedding model we selected at the beginning of the tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "35c411da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7beb196c-7f56-4e4a-8d45-38a8e89632d4', '380dd8f6-3b0f-4a9f-b84a-f7a5ef5726e9', 'abcb1eb9-7ddb-4d0e-af7b-3f0f0d7a4dcc']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deaef69",
   "metadata": {},
   "source": [
    "We use Embeddings to turn text into numerical representations that capture meaning, and then store those embeddings in a VectorStore, which is basically a searchable database for vectors. With this setup, we finish the indexing part of our pipeline: now we have a vector store filled with the blog’s fragmented content. When a user asks a question, we can retrieve the most relevant chunks from the store and then generate an answer by passing both the question and those retrieved pieces to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb551149",
   "metadata": {},
   "source": [
    "We want to build a simple application that takes a user’s question, finds the most relevant documents, and then passes both the question and those documents to a model to generate an answer. To demonstrate this, we’ll show two approaches: first, a RAG agent that performs searches using a basic tool, which works well as a general-purpose solution; and second, a two-step RAG chain that uses only one LLM call per query, making it faster and very effective for straightforward questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93782f9e",
   "metadata": {},
   "source": [
    "### RAG Agents\n",
    "\n",
    "A RAG agent is a simple way to build a RAG application by giving it a tool that can retrieve information. In practice, we can create a minimal agent by implementing a tool that connects directly to our vector store, so the agent can search for relevant text chunks and use them to answer user questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e7df1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2165e7",
   "metadata": {},
   "source": [
    "We build the agent:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "67f066e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "tools = [retrieve_context]\n",
    "prompt = (\n",
    "    \"You have access to a tool that retrieves context from a blog post. \"\n",
    "    \"Use the tool to help answer user queries.\"\n",
    ")\n",
    "agent = create_agent(model, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c31fd",
   "metadata": {},
   "source": [
    "We construct a question that would normally require an iterative sequence of retrieval steps to answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056a4c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcf6517",
   "metadata": {},
   "source": [
    "Note that the agent:\n",
    "- Generates a query to search for a standard method for task decomposition;\n",
    "- Receiving the answer, generates a second query to search for common extensions of it;\n",
    "- Having received all necessary context, answers the question.\n",
    "We can see the full sequence of steps, along with latency and other metadata, in the LangSmith trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f614fba1",
   "metadata": {},
   "source": [
    "Where we see that RAG agents are like AI assistants that first search for relevant information in reliable documents or databases and then use that context to generate a better response. Instead of relying solely on what the model already knows, they combine retrieval and generation, which makes responses more accurate, up-to-date, and based on real sources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
